{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Challenge').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('train.csv', header=True, inferSchema=True)\n",
    "\n",
    "data.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----+-----+--------+--------+-------+------------+\n",
      "|Pclass|   Sex| Age|SibSp|Parch|Embarked|Survived|idx_Sex|idx_Embarked|\n",
      "+------+------+----+-----+-----+--------+--------+-------+------------+\n",
      "|     3|  male|22.0|    1|    0|       S|       0|    0.0|         0.0|\n",
      "|     1|female|38.0|    1|    0|       C|       1|    1.0|         1.0|\n",
      "|     3|female|26.0|    0|    0|       S|       1|    1.0|         0.0|\n",
      "|     1|female|35.0|    1|    0|       S|       1|    1.0|         0.0|\n",
      "|     3|  male|35.0|    0|    0|       S|       0|    0.0|         0.0|\n",
      "+------+------+----+-----+-----+--------+--------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \"\"\" Select the Columns to use \"\"\"\n",
    "selected_data = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Survived']]\n",
    "\n",
    "\n",
    "#\"\"\" Drop the na columns \"\"\"\n",
    "clean_data = selected_data.na.drop()\n",
    "\n",
    "\n",
    "# \"\"\" Encode the String Columns \"\"\"\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer1 = StringIndexer(inputCol=\"Sex\", outputCol=\"idx_Sex\")\n",
    "indexer2 = StringIndexer(inputCol=\"Embarked\", outputCol=\"idx_Embarked\")\n",
    "\n",
    "\n",
    "processed_data = indexer1.fit(clean_data).transform(clean_data)\n",
    "processed_data = indexer2.fit(processed_data).transform(processed_data)\n",
    "\n",
    "processed_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- idx_Sex: double (nullable = false)\n",
      " |-- idx_Embarked: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+-----+-------+------------+\n",
      "|Pclass| Age|SibSp|Parch|idx_Sex|idx_Embarked|\n",
      "+------+----+-----+-----+-------+------------+\n",
      "|     3|22.0|    1|    0|    0.0|         0.0|\n",
      "|     1|38.0|    1|    0|    1.0|         1.0|\n",
      "|     3|26.0|    0|    0|    1.0|         0.0|\n",
      "|     1|35.0|    1|    0|    1.0|         0.0|\n",
      "|     3|35.0|    0|    0|    0.0|         0.0|\n",
      "|     1|54.0|    0|    0|    0.0|         0.0|\n",
      "|     3| 2.0|    3|    1|    0.0|         0.0|\n",
      "|     3|27.0|    0|    2|    1.0|         0.0|\n",
      "|     2|14.0|    1|    0|    1.0|         1.0|\n",
      "|     3| 4.0|    1|    1|    1.0|         0.0|\n",
      "+------+----+-----+-----+-------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'idx_Sex', 'idx_Embarked']\n",
    "processed_data2 = processed_data[processed_features]\n",
    "processed_data2.show(10)\n",
    "# processed_data2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----+-----+--------+--------+-------+------------+--------------------+\n",
      "|Pclass|   Sex| Age|SibSp|Parch|Embarked|Survived|idx_Sex|idx_Embarked|            features|\n",
      "+------+------+----+-----+-----+--------+--------+-------+------------+--------------------+\n",
      "|     3|  male|22.0|    1|    0|       S|       0|    0.0|         0.0|[3.0,22.0,1.0,0.0...|\n",
      "|     1|female|38.0|    1|    0|       C|       1|    1.0|         1.0|[1.0,38.0,1.0,0.0...|\n",
      "|     3|female|26.0|    0|    0|       S|       1|    1.0|         0.0|[3.0,26.0,0.0,0.0...|\n",
      "|     1|female|35.0|    1|    0|       S|       1|    1.0|         0.0|[1.0,35.0,1.0,0.0...|\n",
      "|     3|  male|35.0|    0|    0|       S|       0|    0.0|         0.0|(6,[0,1],[3.0,35.0])|\n",
      "|     1|  male|54.0|    0|    0|       S|       0|    0.0|         0.0|(6,[0,1],[1.0,54.0])|\n",
      "|     3|  male| 2.0|    3|    1|       S|       0|    0.0|         0.0|[3.0,2.0,3.0,1.0,...|\n",
      "|     3|female|27.0|    0|    2|       S|       1|    1.0|         0.0|[3.0,27.0,0.0,2.0...|\n",
      "|     2|female|14.0|    1|    0|       C|       1|    1.0|         1.0|[2.0,14.0,1.0,0.0...|\n",
      "|     3|female| 4.0|    1|    1|       S|       1|    1.0|         0.0|[3.0,4.0,1.0,1.0,...|\n",
      "+------+------+----+-----+-----+--------+--------+-------+------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Split it into features and target \"\"\"\n",
    "processed_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'idx_Sex', 'idx_Embarked']\n",
    "target_column   = ['Survived']\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "\n",
    "vectorizer = VectorAssembler(inputCols=processed_features, outputCol='features')\n",
    "processed_data3 = vectorizer.transform(processed_data)\n",
    "processed_data3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(featuresCol='features', labelCol='Survived')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----+-----+--------+--------+-------+------------+--------------------+\n",
      "|Pclass|   Sex| Age|SibSp|Parch|Embarked|Survived|idx_Sex|idx_Embarked|            features|\n",
      "+------+------+----+-----+-----+--------+--------+-------+------------+--------------------+\n",
      "|     1|female|23.0|    1|    0|       C|       1|    1.0|         1.0|[1.0,23.0,1.0,0.0...|\n",
      "|     1|female|23.0|    3|    2|       S|       1|    1.0|         0.0|[1.0,23.0,3.0,2.0...|\n",
      "|     1|female|26.0|    0|    0|       S|       1|    1.0|         0.0|[1.0,26.0,0.0,0.0...|\n",
      "|     1|female|29.0|    0|    0|       S|       1|    1.0|         0.0|[1.0,29.0,0.0,0.0...|\n",
      "|     1|female|30.0|    0|    0|       C|       1|    1.0|         1.0|[1.0,30.0,0.0,0.0...|\n",
      "+------+------+----+-----+-----+--------+--------+-------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = processed_data3.randomSplit([0.8, 0.2], seed=0)\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_training = random_forest_clf.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf.save(\"lrm_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----+-----+--------+--------+-------+------------+--------------------+--------------------+--------------------+----------+\n",
      "|Pclass|   Sex| Age|SibSp|Parch|Embarked|Survived|idx_Sex|idx_Embarked|            features|       rawPrediction|         probability|prediction|\n",
      "+------+------+----+-----+-----+--------+--------+-------+------------+--------------------+--------------------+--------------------+----------+\n",
      "|     1|female|23.0|    1|    0|       C|       1|    1.0|         1.0|[1.0,23.0,1.0,0.0...|[1.61928679721475...|[0.08096433986073...|       1.0|\n",
      "|     1|female|23.0|    3|    2|       S|       1|    1.0|         0.0|[1.0,23.0,3.0,2.0...|[1.76309502121857...|[0.08815475106092...|       1.0|\n",
      "|     1|female|26.0|    0|    0|       S|       1|    1.0|         0.0|[1.0,26.0,0.0,0.0...|[1.61624658930409...|[0.08081232946520...|       1.0|\n",
      "|     1|female|29.0|    0|    0|       S|       1|    1.0|         0.0|[1.0,29.0,0.0,0.0...|[1.61624658930409...|[0.08081232946520...|       1.0|\n",
      "|     1|female|30.0|    0|    0|       C|       1|    1.0|         1.0|[1.0,30.0,0.0,0.0...|[1.55688942447255...|[0.07784447122362...|       1.0|\n",
      "+------+------+----+-----+-----+--------+--------+-------+------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_test = random_forest_training.transform(df_test)\n",
    "random_forest_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MulticlassClassificationEvaluator(labelCol='Survived', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7929446851843902"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = criterion.evaluate(random_forest_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35717f1c4f95342094abc4f6ac6148258ab8398bdcca50048c184145a1017736"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
